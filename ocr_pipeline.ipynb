{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "import concurrent.futures\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# tesseract\n",
    "import pytesseract\n",
    "\n",
    "# opencv\n",
    "import cv2\n",
    "\n",
    "os.environ['OMP_THREAD_LIMIT'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./is_ocr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>page_body</th>\n",
       "      <th>page_text_extract</th>\n",
       "      <th>page_number</th>\n",
       "      <th>crappy_ocr_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000008_310636853_1</td>\n",
       "      <td>1000008</td>\n",
       "      <td>310636853</td>\n",
       "      <td>RECURSO EXTRAORDINÁRIO 1.000.008 PARANÁ\\n\\nREG...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000008_310653251_1</td>\n",
       "      <td>1000008</td>\n",
       "      <td>310653251</td>\n",
       "      <td>Ó%/aléúnn O%ÃÁ///IM/ O%/k]fa/</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000008_310958131_1</td>\n",
       "      <td>1000008</td>\n",
       "      <td>310958131</td>\n",
       "      <td>&amp;ª fezaek Zã..í.</td>\n",
       "      <td>Supremo Tribuna...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000032_310629282_1</td>\n",
       "      <td>1000032</td>\n",
       "      <td>310629282</td>\n",
       "      <td>RECURSO EXTRAORDINÁRIO COM AGRAVO 1.000.032 MA...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000035_15338842013_1</td>\n",
       "      <td>1000035</td>\n",
       "      <td>15338842013</td>\n",
       "      <td>á? fezaki Z É Ád\\nQ%gãaú %Wegwâdwção&amp;%wa\\n\\nAR...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       process_id  document_id  \\\n",
       "id                                               \n",
       "1000008_310636853_1       1000008    310636853   \n",
       "1000008_310653251_1       1000008    310653251   \n",
       "1000008_310958131_1       1000008    310958131   \n",
       "1000032_310629282_1       1000032    310629282   \n",
       "1000035_15338842013_1     1000035  15338842013   \n",
       "\n",
       "                                                               page_body  \\\n",
       "id                                                                         \n",
       "1000008_310636853_1    RECURSO EXTRAORDINÁRIO 1.000.008 PARANÁ\\n\\nREG...   \n",
       "1000008_310653251_1                        Ó%/aléúnn O%ÃÁ///IM/ O%/k]fa/   \n",
       "1000008_310958131_1                                     &ª fezaek Zã..í.   \n",
       "1000032_310629282_1    RECURSO EXTRAORDINÁRIO COM AGRAVO 1.000.032 MA...   \n",
       "1000035_15338842013_1  á? fezaki Z É Ád\\nQ%gãaú %Wegwâdwção&%wa\\n\\nAR...   \n",
       "\n",
       "                                                       page_text_extract  \\\n",
       "id                                                                         \n",
       "1000008_310636853_1                                                  ...   \n",
       "1000008_310653251_1                                                  ...   \n",
       "1000008_310958131_1                                   Supremo Tribuna...   \n",
       "1000032_310629282_1                                                  ...   \n",
       "1000035_15338842013_1                                                ...   \n",
       "\n",
       "                       page_number crappy_ocr_text  \n",
       "id                                                  \n",
       "1000008_310636853_1              1            None  \n",
       "1000008_310653251_1              1            None  \n",
       "1000008_310958131_1              1            None  \n",
       "1000032_310629282_1              1            None  \n",
       "1000035_15338842013_1            1            None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unused columns\n",
    "unused_columns = [\n",
    "    'process_class',\n",
    "    'process_processing_date',\n",
    "    'page_is_ocr',\n",
    "    'process_process_time',\n",
    "    'process_is_complete',\n",
    "    'document_processing_date',\n",
    "    'document_processing_time',\n",
    "    'page_image',\n",
    "    'page_piece'\n",
    "]\n",
    "new_df = df\n",
    "for column in unused_columns:\n",
    "    new_df = new_df.drop(column, axis=1)\n",
    "    \n",
    "# add new column to dataframe\n",
    "new_df['crappy_ocr_text'] = None\n",
    "    \n",
    "# add new column to join process_id and document_id\n",
    "new_df['id'] = new_df['process_id'].map(lambda x: str(x) + '_') + new_df['document_id'].map(lambda x: str(x) + '_') + new_df['page_number'].map(str)\n",
    "new_df = new_df.set_index('id')\n",
    "new_df = new_df.sort_index()\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_add_to_df(path):\n",
    "    \"\"\"\n",
    "    Receive a image path, extract it's content using tesseract and add it to dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # get image id\n",
    "    current_id = re.sub('./crappy_images\\/crappy_([\\d]+_[\\d]+_[\\d]+)\\.jpg', '\\\\1', path)\n",
    "\n",
    "    # read image\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    # extract text\n",
    "    text = pytesseract.image_to_string(image, lang='por+eng')\n",
    "    \n",
    "#     # add to dataframe\n",
    "#     new_df.loc[current_id, 'crappy_ocr_text'] = text\n",
    "    return [current_id, text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-11 00:08:36] Info: Pipeline has started. Ammount of data: 80624\n",
      "[2019-11-11 00:12:24] Info: Pipeline has processed and generated 1000 crappy images.\n",
      "[2019-11-11 00:15:51] Info: Pipeline has processed and generated 2000 crappy images.\n",
      "[2019-11-11 00:19:13] Info: Pipeline has processed and generated 3000 crappy images.\n",
      "[2019-11-11 00:23:10] Info: Pipeline has processed and generated 4000 crappy images.\n",
      "[2019-11-11 00:26:26] Info: Pipeline has processed and generated 5000 crappy images.\n",
      "[2019-11-11 00:29:34] Info: Pipeline has processed and generated 6000 crappy images.\n",
      "[2019-11-11 00:32:57] Info: Pipeline has processed and generated 7000 crappy images.\n",
      "[2019-11-11 00:36:14] Info: Pipeline has processed and generated 8000 crappy images.\n",
      "[2019-11-11 00:39:57] Info: Pipeline has processed and generated 9000 crappy images.\n",
      "[2019-11-11 00:43:35] Info: Pipeline has processed and generated 10000 crappy images.\n",
      "[2019-11-11 00:46:33] Info: Pipeline has processed and generated 11000 crappy images.\n",
      "[2019-11-11 00:50:07] Info: Pipeline has processed and generated 12000 crappy images.\n",
      "[2019-11-11 00:53:19] Info: Pipeline has processed and generated 13000 crappy images.\n",
      "[2019-11-11 00:56:13] Info: Pipeline has processed and generated 14000 crappy images.\n",
      "[2019-11-11 00:59:35] Info: Pipeline has processed and generated 15000 crappy images.\n",
      "[2019-11-11 01:02:25] Info: Pipeline has processed and generated 16000 crappy images.\n",
      "[2019-11-11 01:05:34] Info: Pipeline has processed and generated 17000 crappy images.\n",
      "[2019-11-11 01:08:29] Info: Pipeline has processed and generated 18000 crappy images.\n",
      "[2019-11-11 01:12:10] Info: Pipeline has processed and generated 19000 crappy images.\n",
      "[2019-11-11 01:15:32] Info: Pipeline has processed and generated 20000 crappy images.\n",
      "[2019-11-11 01:19:00] Info: Pipeline has processed and generated 21000 crappy images.\n",
      "[2019-11-11 01:22:22] Info: Pipeline has processed and generated 22000 crappy images.\n",
      "[2019-11-11 01:25:35] Info: Pipeline has processed and generated 23000 crappy images.\n",
      "[2019-11-11 01:28:55] Info: Pipeline has processed and generated 24000 crappy images.\n",
      "[2019-11-11 01:32:22] Info: Pipeline has processed and generated 25000 crappy images.\n",
      "[2019-11-11 01:35:51] Info: Pipeline has processed and generated 26000 crappy images.\n",
      "[2019-11-11 01:39:00] Info: Pipeline has processed and generated 27000 crappy images.\n",
      "[2019-11-11 01:41:56] Info: Pipeline has processed and generated 28000 crappy images.\n",
      "[2019-11-11 01:44:52] Info: Pipeline has processed and generated 29000 crappy images.\n",
      "[2019-11-11 01:48:05] Info: Pipeline has processed and generated 30000 crappy images.\n",
      "[2019-11-11 01:51:45] Info: Pipeline has processed and generated 31000 crappy images.\n",
      "[2019-11-11 01:55:08] Info: Pipeline has processed and generated 32000 crappy images.\n",
      "[2019-11-11 01:58:54] Info: Pipeline has processed and generated 33000 crappy images.\n",
      "[2019-11-11 02:02:25] Info: Pipeline has processed and generated 34000 crappy images.\n",
      "[2019-11-11 02:05:40] Info: Pipeline has processed and generated 35000 crappy images.\n",
      "[2019-11-11 02:08:58] Info: Pipeline has processed and generated 36000 crappy images.\n",
      "[2019-11-11 02:11:52] Info: Pipeline has processed and generated 37000 crappy images.\n",
      "[2019-11-11 02:14:53] Info: Pipeline has processed and generated 38000 crappy images.\n",
      "[2019-11-11 02:18:28] Info: Pipeline has processed and generated 39000 crappy images.\n",
      "[2019-11-11 02:21:53] Info: Pipeline has processed and generated 40000 crappy images.\n",
      "[2019-11-11 02:25:14] Info: Pipeline has processed and generated 41000 crappy images.\n",
      "[2019-11-11 02:28:45] Info: Pipeline has processed and generated 42000 crappy images.\n",
      "[2019-11-11 02:32:26] Info: Pipeline has processed and generated 43000 crappy images.\n",
      "[2019-11-11 02:35:46] Info: Pipeline has processed and generated 44000 crappy images.\n",
      "[2019-11-11 02:38:49] Info: Pipeline has processed and generated 45000 crappy images.\n",
      "[2019-11-11 02:41:47] Info: Pipeline has processed and generated 46000 crappy images.\n",
      "[2019-11-11 02:45:20] Info: Pipeline has processed and generated 47000 crappy images.\n",
      "[2019-11-11 02:48:38] Info: Pipeline has processed and generated 48000 crappy images.\n",
      "[2019-11-11 02:52:02] Info: Pipeline has processed and generated 49000 crappy images.\n",
      "[2019-11-11 02:55:19] Info: Pipeline has processed and generated 50000 crappy images.\n",
      "[2019-11-11 02:58:33] Info: Pipeline has processed and generated 51000 crappy images.\n",
      "[2019-11-11 03:01:49] Info: Pipeline has processed and generated 52000 crappy images.\n",
      "[2019-11-11 03:05:22] Info: Pipeline has processed and generated 53000 crappy images.\n",
      "[2019-11-11 03:09:11] Info: Pipeline has processed and generated 54000 crappy images.\n",
      "[2019-11-11 03:12:38] Info: Pipeline has processed and generated 55000 crappy images.\n",
      "[2019-11-11 03:15:49] Info: Pipeline has processed and generated 56000 crappy images.\n",
      "[2019-11-11 03:18:49] Info: Pipeline has processed and generated 57000 crappy images.\n",
      "[2019-11-11 03:22:14] Info: Pipeline has processed and generated 58000 crappy images.\n",
      "[2019-11-11 03:25:24] Info: Pipeline has processed and generated 59000 crappy images.\n",
      "[2019-11-11 03:28:40] Info: Pipeline has processed and generated 60000 crappy images.\n",
      "[2019-11-11 03:31:55] Info: Pipeline has processed and generated 61000 crappy images.\n",
      "[2019-11-11 03:35:53] Info: Pipeline has processed and generated 62000 crappy images.\n",
      "[2019-11-11 03:39:03] Info: Pipeline has processed and generated 63000 crappy images.\n",
      "[2019-11-11 03:42:07] Info: Pipeline has processed and generated 64000 crappy images.\n",
      "[2019-11-11 03:45:43] Info: Pipeline has processed and generated 65000 crappy images.\n",
      "[2019-11-11 03:48:50] Info: Pipeline has processed and generated 66000 crappy images.\n",
      "[2019-11-11 03:52:29] Info: Pipeline has processed and generated 67000 crappy images.\n",
      "[2019-11-11 03:55:34] Info: Pipeline has processed and generated 68000 crappy images.\n",
      "[2019-11-11 03:59:14] Info: Pipeline has processed and generated 69000 crappy images.\n",
      "[2019-11-11 04:02:09] Info: Pipeline has processed and generated 70000 crappy images.\n",
      "[2019-11-11 04:05:46] Info: Pipeline has processed and generated 71000 crappy images.\n",
      "[2019-11-11 04:09:14] Info: Pipeline has processed and generated 72000 crappy images.\n",
      "[2019-11-11 04:12:27] Info: Pipeline has processed and generated 73000 crappy images.\n",
      "[2019-11-11 04:15:42] Info: Pipeline has processed and generated 74000 crappy images.\n",
      "[2019-11-11 04:19:12] Info: Pipeline has processed and generated 75000 crappy images.\n",
      "[2019-11-11 04:22:42] Info: Pipeline has processed and generated 76000 crappy images.\n",
      "[2019-11-11 04:26:14] Info: Pipeline has processed and generated 77000 crappy images.\n",
      "[2019-11-11 04:29:19] Info: Pipeline has processed and generated 78000 crappy images.\n",
      "[2019-11-11 04:32:41] Info: Pipeline has processed and generated 79000 crappy images.\n",
      "[2019-11-11 04:36:00] Info: Pipeline has processed and generated 80000 crappy images.\n"
     ]
    }
   ],
   "source": [
    "crappy_folder = './crappy_images/'\n",
    "\n",
    "image_list = glob(crappy_folder + '*.jpg')\n",
    "size = len(image_list)\n",
    "\n",
    "values = []\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=6) as executor:\n",
    "    count = 0\n",
    "    current_line = 0\n",
    "    times = 0\n",
    "    print('[{}] Info: Pipeline has started. Ammount of data: {}'.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), size))\n",
    "    for img_path, result in zip(image_list, executor.map(extract_and_add_to_df, image_list)):\n",
    "        values.append(result)\n",
    "        current_line += 1\n",
    "        count += 1\n",
    "        if count == 1000:\n",
    "            times += 1\n",
    "            print('[{}] Info: Pipeline has processed and generated {} crappy images.'.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), times * count))\n",
    "            count = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in values:\n",
    "    current_id, text = value\n",
    "    new_df.loc[current_id, 'crappy_ocr_text'] = text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('./ocr_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
